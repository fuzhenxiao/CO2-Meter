kernel_type = {
    "input": {"code": 1},
    "attn_norm": {"code": 2},
    "q_proj": {"code": 3},
    "k_proj": {"code": 4},
    "v_proj": {"code": 5},
    "qk_matmul": {"code": 6},
    "softmax": {"code": 7},
    "sv_matmul": {"code": 8},
    "out_proj": {"code": 9},
    "attn_add": {"code": 10},
    "mlp_norm": {"code": 11},
    "gate_proj": {"code": 12},
    "up_proj": {"code": 13},
    "mlp_act": {"code": 14},
    "down_proj": {"code": 15},
    "mlp_add": {"code": 16},
    "output": {"code": 17},
    "fused_attention": {"code": 18},
}

llm_type = {
    "bloom": {"code": 1},
    "llama": {"code": 2},
    "gemma": {"code": 3},
    "gemma2": {"code": 4},
    "phi3": {"code": 5},
    "qwen2": {"code": 6},
    "mixtral": {"code": 7},
    "internlm": {"code": 8},
    "tinyllama": {"code": 9},
    "qwen2-0.5": {"code": 9},

}

act_type = {
    "silu": {"code": 1},
    "gelu": {"code": 2},
    "gelu_pytorch_tanh": {"code": 3},
    "SwiGLU": {"code": 4},
}


avaliable_model_ids_sources = {
    "internlm/internlm2-chat-1_8b": {"source": "huggingface", "file": "internlm.py"},
    "meta-llama/Llama-2-7b-hf": {"source": "huggingface", "file": "Llama.py"},
    "TinyLlama/TinyLlama-1.1B-Chat-v1.0": {"source": "huggingface", "file": "tinyllama.py"},
    "meta-llama/Llama-2-13b-hf": {"source": "huggingface", "file": "Llama.py"},
    "meta-llama/Llama-2-70b-hf": {"source": "huggingface", "file": "Llama.py"},
    "EleutherAI/gpt-j-6B": {"source": "huggingface", "file": "gpt-j-6B.py"},
    "THUDM/chatglm3-6b": {"source": "huggingface", "file": "chatglm3.py"},
    "facebook/opt-125m": {"source": "huggingface", "file": "opt.py"},
    "facebook/opt-1.3b": {"source": "huggingface", "file": "opt.py"},
    "facebook/opt-2.7b": {"source": "huggingface", "file": "opt.py"},
    "facebook/opt-6.7b": {"source": "huggingface", "file": "opt.py"},
    "facebook/opt-30b": {"source": "huggingface", "file": "opt.py"},
    "facebook/opt-66b": {"source": "huggingface", "file": "opt.py"},
    "bigscience/bloom-560m": {"source": "huggingface", "file": "bloom.py"},
    "bigscience/bloom-1b1": {"source": "huggingface", "file": "bloom.py"},
    "bigscience/bloom-1b7": {"source": "huggingface", "file": "bloom.py"},
    "bigscience/bloom-3b": {"source": "huggingface", "file": "bloom.py"},
    "bigscience/bloom-7b1": {"source": "huggingface", "file": "bloom.py"},
    "bigscience/bloom": {"source": "huggingface", "file": "bloom.py"},
    "google/gemma-2b": {"source": "huggingface", "file": "gemma.py"},
    "google/gemma-7b": {"source": "huggingface", "file": "gemma.py"},
    "google/gemma-2-2b": {"source": "huggingface", "file": "gemma2.py"},
    "google/gemma-2-9b": {"source": "huggingface", "file": "gemma2.py"},
    "google/gemma-2-27b": {"source": "huggingface", "file": "gemma2.py"},
    "microsoft/Phi-3-mini-128k-instruct": {"source": "huggingface", "file": "phi3.py"},
    "Qwen/Qwen2-0.5B": {"source": "huggingface", "file": "Qwen2.py"},
    "Qwen/Qwen2-1.5B": {"source": "huggingface", "file": "Qwen2.py"},
    "Qwen/Qwen1.5-0.5B": {"source": "huggingface", "file": "Qwen1p5.py"},
    "Qwen/Qwen2-7B": {"source": "huggingface", "file": "Qwen2.py"},
    "Qwen/Qwen2-72B": {"source": "huggingface", "file": "Qwen2.py"},
    "mistralai/Mixtral-8x7B-v0.1": {"source": "huggingface", "file": "mixtral.py"},
    # "DiT-XL/2": {"source": "DiT"},
    # "DiT-XL/4": {"source": "DiT"},
}
avaliable_model_ids = [_ for _ in avaliable_model_ids_sources.keys()]
